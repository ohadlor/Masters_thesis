

\makeatletter\Hy@SaveLastskip\label{proofsection:prAtEndii}\ifdefined\pratend@current@sectionlike@label\immediate\write\@auxout{\string\gdef\string\pratend@section@for@proofii{\pratend@current@sectionlike@label}}\fi\Hy@RestoreLastskip\makeatother\begin{proof}[Proof of \pratendRef{thm:prAtEndii}]\phantomsection\label{proof:prAtEndii}\begin {align*} \expectation {f(\RV )}{\RV } & = \expectation {f(\RV )\1{\RV \in \subSpace }}{\RV }+ \expectation {f(\RV )\1{\RV \in \stcomp {\subSpace }}}{\RV } \\ & \leq \expectation {f(\RV )\1{\RV \in \subSpace }}{\RV } +M_f(\stcomp {\subSpace })\expectation {\1{\RV \in \stcomp {\subSpace }}}{\RV } \\ & =\expectation {f(\RV )\1{\RV \in \subSpace }}{\RV } +M_f(\stcomp {\subSpace })\measure {\stcomp {\subSpace }} \\ & =\partialexpectation {f(\RV )}{\subSpace } +M_f(\stcomp {\subSpace })\measure {\stcomp {\subSpace }}\qed \end {align*}\end{proof}

\makeatletter\Hy@SaveLastskip\label{proofsection:prAtEndiii}\ifdefined\pratend@current@sectionlike@label\immediate\write\@auxout{\string\gdef\string\pratend@section@for@proofiii{\pratend@current@sectionlike@label}}\fi\Hy@RestoreLastskip\makeatother\begin{proof}[Proof of \pratendRef{thm:prAtEndiii}]\phantomsection\label{proof:prAtEndiii}The proof is similar to that of \cref {thm:general_bounds}, but with an extra step, \begin {align*} \expectation {f(\RV )}{\RV } & = \expectation {f(\RV )\1{\RV \in \subSpace }}{\RV }+ \expectation {f(\RV )\1{\RV \in \stcomp {\subSpace }}}{\RV } \\&=\expectation {f(\RV )\1{\RV \in \subSpace }}{\RV }+\sum _{i=1}^N\expectation {f(\RV )\1{\RV \in \stcompI {\subSpace }{i}}}{\RV }\\ &\leq \partialexpectation {f(\RV )}{\subSpace } +\sum _{i=1}^NM_f(\stcompI {\subSpace }{i})\measure {\stcompI {\subSpace }{i}}\qed \end {align*}\end{proof}

\makeatletter\Hy@SaveLastskip\label{proofsection:prAtEndiv}\ifdefined\pratend@current@sectionlike@label\immediate\write\@auxout{\string\gdef\string\pratend@section@for@proofiv{\pratend@current@sectionlike@label}}\fi\Hy@RestoreLastskip\makeatother\begin{proof}[Proof of \pratendRef{thm:prAtEndiv}]\phantomsection\label{proof:prAtEndiv}From \cref {thm:general_bounds} we have \begin {align*} \expectation {f(\RV )}{\RV } & \leq \partialexpectation {f(\RV )}{\subSpace } +M_f(\stcomp {\subSpace })\measure {\stcomp {\subSpace }} \intertext {Given that $\subSpace ^\prime \subseteq \subSpace $, then $\stcomp {\subSpace }\subseteq \stcomp {\subSpace ^\prime }$\;, leading directly to $M_f(\stcomp {\subSpace })\leq M_f(\stcomp {\subSpace ^\prime })$, thus} & \leq \partialexpectation {f(\RV )}{\subSpace } +M_f(\stcomp {\subSpace ^\prime })\measure {\stcomp {\subSpace }}\qed \end {align*}\end{proof}

\makeatletter\Hy@SaveLastskip\label{proofsection:prAtEndv}\ifdefined\pratend@current@sectionlike@label\immediate\write\@auxout{\string\gdef\string\pratend@section@for@proofv{\pratend@current@sectionlike@label}}\fi\Hy@RestoreLastskip\makeatother\begin{proof}[Proof of \pratendRef{thm:prAtEndv}]\phantomsection\label{proof:prAtEndv}By definition of $\subSpace $, $M_f(\stcomp {\subSpace })\leq \varepsilon ^\prime $, thus \begin {equation*} \expectation {f(\RV )}{\RV }\leq \partialexpectation {f(\RV )}{\subSpace } +\varepsilon ^\prime \measure {\stcomp {\subSpace }}\qed \end {equation*}\end{proof}

\makeatletter\Hy@SaveLastskip\label{proofsection:prAtEndvi}\ifdefined\pratend@current@sectionlike@label\immediate\write\@auxout{\string\gdef\string\pratend@section@for@proofvi{\pratend@current@sectionlike@label}}\fi\Hy@RestoreLastskip\makeatother\begin{proof}[Proof of \pratendRef{thm:prAtEndvi}]\phantomsection\label{proof:prAtEndvi}We begin by applying \cref {thm:general_bounds} to the inner expectation \begin {align*} \expectation {\expectation {f(\RV ,\RVI )}{\RVI \mid \RV }}{\RV } & \leq \E _{\RV }\Bigl [\partialexpectation {f(\RV ,\RVI )}{\subSpaceI {\variableI }(\RV )}+M_f(\RV ,\stcomp {\subSpaceI {\variableI }(\RV )})\measure {\stcomp {\subSpaceI {\variableI }(\RV )}}\Bigr ]\\ \intertext {Now applying \cref {thm:general_bounds} to the outer expectation} \begin {split} &\leq \partialexpectation {\partialexpectation {f(\RV ,\RVI )}{\subSpaceI {\variableI }(\RV )}}{\subSpaceI {\variable }} +\partialexpectation {M_f(\RV ,\stcompI {\subSpace }{\variableI }(\RV ))\measure {\stcompI {\subSpace }{\variableI }(\RV )}}{\subSpaceI {\variable }} \\ & \phantomeq +\measure {\stcompI {\subSpace }{\variable }}\sup _{\variable \in \stcompI {\subSpace }{\variable }}\partialexpectation {f(\variable ,\RVI )}{\subSpaceI {\variableI }(\variable )}\\ &\phantomeq +\measure {\stcompI {\subSpace }{\variable }}\sup _{\variable \in \stcompI {\subSpace }{\variable }}\left \{\measure {\stcompI {\subSpace }{\variableI }(\variable )}M_f\left (\variable ,\stcompI {\subSpace }{\variableI }(\variable )\right )\right \}\qed \end {split} \end {align*}\end{proof}

\makeatletter\Hy@SaveLastskip\label{proofsection:prAtEndvii}\ifdefined\pratend@current@sectionlike@label\immediate\write\@auxout{\string\gdef\string\pratend@section@for@proofvii{\pratend@current@sectionlike@label}}\fi\Hy@RestoreLastskip\makeatother\begin{proof}[Proof of \pratendRef{thm:prAtEndvii}]\phantomsection\label{proof:prAtEndvii}Given that the r.v.s and subsets are independent, \cref {thm:bound_multi_cond} simplifies trivially to the bounds\end{proof}

\makeatletter\Hy@SaveLastskip\label{proofsection:prAtEndviii}\ifdefined\pratend@current@sectionlike@label\immediate\write\@auxout{\string\gdef\string\pratend@section@for@proofviii{\pratend@current@sectionlike@label}}\fi\Hy@RestoreLastskip\makeatother\begin{proof}[Proof of \pratendRef{thm:prAtEndviii}]\phantomsection\label{proof:prAtEndviii}\begin {align*} \expectation {f(\RV ,\RVI )}{\RV ,\RVI }-\partialexpectation {\partialexpectation {f(\RV ,\RVI )}{\subSpaceI {\variableI }}}{\subSpaceI {\variable }} & \leq M_f(\stcomp {\subSpace ^\prime })\measure {\stcomp {\subSpace ^\prime }} \\ & =M_f(\stcomp {\subSpace ^\prime })\left (1-\measure {\subSpaceI {\variable }\times \subSpaceI {\variableI }}\right ) \\ & =M_f(\stcomp {\subSpace ^\prime })\left (1-\measure {\subSpaceI {\variable }}\measure {\subSpaceI {\variableI }}\right )\qed \end {align*}\end{proof}

\makeatletter\Hy@SaveLastskip\label{proofsection:prAtEndix}\ifdefined\pratend@current@sectionlike@label\immediate\write\@auxout{\string\gdef\string\pratend@section@for@proofix{\pratend@current@sectionlike@label}}\fi\Hy@RestoreLastskip\makeatother\begin{proof}[Proof of \pratendRef{thm:prAtEndix}]\phantomsection\label{proof:prAtEndix}Assuming $g(\variable )\geq 0$ \begin {equation*} M_f(\stcomp {\subSpace })=\max _{\variable \in \stcomp {\subSpace }}\{g(\variable )\log h(\variable )\}\leq \max \left \{ \begin {aligned} & M_g(\stcomp {\subSpace })\log M_h(\stcomp {\subSpace })\;, \\ & m_g(\stcomp {\subSpace })\log M_h(\stcomp {\subSpace }) \end {aligned}\right \}\qed \end {equation*} The assumption of $g(\variable )\geq 0$ can also be easily dropped for a more general bound.\end{proof}

\makeatletter\Hy@SaveLastskip\label{proofsection:prAtEndx}\ifdefined\pratend@current@sectionlike@label\immediate\write\@auxout{\string\gdef\string\pratend@section@for@proofx{\pratend@current@sectionlike@label}}\fi\Hy@RestoreLastskip\makeatother\begin{proof}[Proof of \pratendRef{thm:prAtEndx}]\phantomsection\label{proof:prAtEndx}\begin {align*} \expectation {\expectation {\log f(\RV ,\RVI )}{\RVI \mid \RV }}{\RV }&=\expectation {\expectation {\log \frac {f(\RV ,\RVI )}{\varepsilon (\RVI )}}{\RVI \mid \RV }}{\RV }+\expectation {\expectation {\log \varepsilon (\RVI )}{\RVI \mid \RV }}{\RV } \\ &=\expectation {\expectation {\log \frac {f(\RV ,\RVI )}{\varepsilon (\RVI )}}{\RVI \mid \RV }}{\RV }+\expectation {\log \varepsilon (\RVI )}{\RVI } \\ \begin {split} &\leq \partialexpectation {\expectation {\log f(\RV ,\RVI )}{\RVI \mid \RV }}{\subSpace }-\partialexpectation {\expectation {\log \varepsilon (\RVI )}{\RVI \mid \RV }}{\subSpace }\\ &\phantomeq +\left (1-\measure {\subSpace }\right )\log \max _{\variableI }\varepsilon (\variableI )+\expectation {\log \varepsilon (\RVI )}{\RVI }\qedhere \end {split} \end {align*}\end{proof}

\makeatletter\Hy@SaveLastskip\label{proofsection:prAtEndxi}\ifdefined\pratend@current@sectionlike@label\immediate\write\@auxout{\string\gdef\string\pratend@section@for@proofxi{\pratend@current@sectionlike@label}}\fi\Hy@RestoreLastskip\makeatother\begin{proof}[Proof of \pratendRef{thm:prAtEndxi}]\phantomsection\label{proof:prAtEndxi}\begin {align*} \partialexpectation {f(\RV )}{\subSpace ^\prime } & =\expectation {f(\RV )\1{\RV \in \subSpace ^\prime }}{}\\ & =\expectation {f(\RV )\left (\1{\RV \in \subSpace }+\1{\RV \in \subSpace _{\textrm {\textup {new}}}}\right )}{}\\ & =\partialexpectation {f(\RV )}{\subSpace }+\partialexpectation {f(\RV )}{\subSpace _{\textrm {\textup {new}}}} \end {align*} The proof for $\measure {\subSpace ^\prime }$ follows the same logic. \par $\stcomp {\subSpace }=\subSpace _{\textrm {\textup {new}}}\cup \stcomp {\subSpace ^\prime }$, thus $M_f(\stcomp {\subSpace })=\max \{M_f(\subSpace _{\textrm {\textup {new}}}),M_f(\stcomp {\subSpace ^\prime })\}$, if $M_f(\stcomp {\subSpace })>M_f(\subSpace _{\textrm {\textup {new}}})$, then implicitly $M_f(\stcomp {\subSpace })\neq M_f(\subSpace _{\textrm {\textup {new}}})$ leaving us with $M_f(\stcomp {\subSpace })=M_f(\stcomp {\subSpace ^\prime })$. If $M_f(\stcomp {\subSpace })=M_f(\subSpace _{\textrm {\textup {new}}})$ then we gain no information on $M_f(\stcomp {\subSpace ^\prime })$, leaving us with $M_f(\stcomp {\subSpace })\geq M_f(\stcomp {\subSpace ^\prime })$.\end{proof}

\makeatletter\Hy@SaveLastskip\label{proofsection:prAtEndxii}\ifdefined\pratend@current@sectionlike@label\immediate\write\@auxout{\string\gdef\string\pratend@section@for@proofxii{\pratend@current@sectionlike@label}}\fi\Hy@RestoreLastskip\makeatother\begin{proof}[Proof of \pratendRef{thm:prAtEndxii}]\phantomsection\label{proof:prAtEndxii}By definition $\measure {\Space }=1$ and $\partialexpectation {f(\RV )}{\Space }=\expectation {f(\RV )}{\RV }$, thus we immediately arrive at $\lowerbound (\Space )=\upperbound (\Space )=0$\end{proof}

\makeatletter\Hy@SaveLastskip\label{proofsection:prAtEndxiii}\ifdefined\pratend@current@sectionlike@label\immediate\write\@auxout{\string\gdef\string\pratend@section@for@proofxiii{\pratend@current@sectionlike@label}}\fi\Hy@RestoreLastskip\makeatother\begin{proof}[Proof of \pratendRef{thm:prAtEndxiii}]\phantomsection\label{proof:prAtEndxiii}Let us define $\subSpace ^\prime \supseteq \subSpace $, thus $M_f(\stcomp {\subSpace ^\prime })\leq M_f(\stcomp {\subSpace })$, by \cref {thm:incrementality} we find that $\measure {\subSpace }\leq \measure {\subSpace ^\prime }$ thus \begin {equation*} M_f(\stcomp {\subSpace ^\prime })\left (1-\measure {\subSpace ^\prime }\right ) \leq M_f(\stcomp {\subSpace })\left (1-\measure {\subSpace }\right )\qed \end {equation*}\end{proof}

\makeatletter\Hy@SaveLastskip\label{proofsection:prAtEndxiv}\ifdefined\pratend@current@sectionlike@label\immediate\write\@auxout{\string\gdef\string\pratend@section@for@proofxiv{\pratend@current@sectionlike@label}}\fi\Hy@RestoreLastskip\makeatother\begin{proof}[Proof of \pratendRef{thm:prAtEndxiv}]\phantomsection\label{proof:prAtEndxiv}\begin {align*} \min _i \weight {}{i} & =\min _i \frac {\prob {\variable ^i}}{\sum _{i=1}^N\prob {\variable ^i}} \intertext {Let us denote, without loss of generality, $\min \limits _i \prob {\variable ^i}$ as $\prob {\variable ^1}$, thus} & =\frac {\prob {\variable ^1}}{\prob {\variable ^1}+\sum _{i=2}^N\prob {\variable ^i}} \\ & \geq \frac {\prob {\variable ^1}}{\prob {\variable ^1}+(N-1)\max \limits _i\prob {\variable ^i}} \\ & \geq \frac {\min \prob {\variable }}{\min \prob {\variable }+(N-1)\max \prob {\variable }}\qed \end {align*}\end{proof}

\makeatletter\Hy@SaveLastskip\label{proofsection:prAtEndxv}\ifdefined\pratend@current@sectionlike@label\immediate\write\@auxout{\string\gdef\string\pratend@section@for@proofxv{\pratend@current@sectionlike@label}}\fi\Hy@RestoreLastskip\makeatother\begin{proof}[Proof of \pratendRef{thm:prAtEndxv}]\phantomsection\label{proof:prAtEndxv}From Hoeffding's inequality on the r.v. $f(\RV )$ the following holds \begin {equation*} \prob {\abs {\expectation {f(\RV )}{}-\estimator {f(\RV )}{}}\leq t}\geq 1-\delta , \end {equation*} where $t=\sqrt {\frac {\Delta _f^2}{2N}\log \frac {2}{\delta }}$. From the absolute value we have two inequalities, we fill focus on the upper bound. With the addition of inequality \refeq {eq:bound_upper} for some subset $\subSpace _n$ of the samples \begin {align*} & \expectation {f(\RV )}{}-\estimator {f(\RV )}{}+\estimator {f(\RV )}{}-\partialestimator {f(\RV )}{\subSpace }\leq t+M_f(\stcomp {\subSpace })\estimatedmeasure {\stcomp {\subSpace }}, \\ & \expectation {f(\RV )}{}-\partialestimator {f(\RV )}{\subSpace }\leq t+M_f(\stcomp {\subSpace })\estimatedmeasure {\stcomp {\subSpace }}. \end {align*} Repeating the procedure for the lower bounds results in the complete bounds.\end{proof}

\makeatletter\Hy@SaveLastskip\label{proofsection:prAtEndxvi}\ifdefined\pratend@current@sectionlike@label\immediate\write\@auxout{\string\gdef\string\pratend@section@for@proofxvi{\pratend@current@sectionlike@label}}\fi\Hy@RestoreLastskip\makeatother\begin{proof}[Proof of \pratendRef{thm:prAtEndxvi}]\phantomsection\label{proof:prAtEndxvi}From Hoeffding's inequality on the r.v. $f(\RV )$ the following holds \begin {equation*} \prob {\abs {\condexpectation {f(\RV )}{\subSpace }{}-\condestimator {f(\RV )}{\subSpace }{}}\leq t}\geq 1-\delta \;, \end {equation*} where $t=\sqrt {\frac {\Delta _f^2}{2N}\log \frac {2}{\delta }}$. From the absolute value we have two inequalities, we fill focus on the upper bound. Multiplying though by $\measure {\subSpace }$ and the addition of inequality \refeq {eq:bound_upper} we find \begin {align*} & \partialexpectation {f(\RV )}{\subSpace }-\measure {\subSpace }\condestimator {f(\RV )}{\subSpace }{}\leq \measure {\subSpace }t\;,\\ \begin {split} & \expectation {f(\RV )}{}-\partialexpectation {f(\RV )}{\subSpace }+\partialexpectation {f(\RV )}{\subSpace }-\measure {\subSpace }\condestimator {f(\RV )}{\subSpace }{} \\ & \leq \measure {\subSpace }t+M_f(\stcomp {\subSpace })\measure {\stcomp {\subSpace }}\;, \end {split} \\ & \expectation {f(\RV )}{}-\measure {\subSpace }\condestimator {f(\RV )}{\subSpace }{}\leq \measure {\subSpace }t+M_f(\stcomp {\subSpace })\measure {\stcomp {\subSpace }}\;. \end {align*}\end{proof}

\makeatletter\Hy@SaveLastskip\label{proofsection:prAtEndxvii}\ifdefined\pratend@current@sectionlike@label\immediate\write\@auxout{\string\gdef\string\pratend@section@for@proofxvii{\pratend@current@sectionlike@label}}\fi\Hy@RestoreLastskip\makeatother\begin{proof}[Proof of \pratendRef{thm:prAtEndxvii}]\phantomsection\label{proof:prAtEndxvii}Applying \cref {thm:general_bounds} to $\expectation {\boldsymbol {R}_l}{\states {l}}$ and summing for the cumulative reward results in the desired bounds.\end{proof}

\makeatletter\Hy@SaveLastskip\label{proofsection:prAtEndxviii}\ifdefined\pratend@current@sectionlike@label\immediate\write\@auxout{\string\gdef\string\pratend@section@for@proofxviii{\pratend@current@sectionlike@label}}\fi\Hy@RestoreLastskip\makeatother\begin{proof}[Proof of \pratendRef{thm:prAtEndxviii}]\phantomsection\label{proof:prAtEndxviii}Proof by induction: \par \textbf {\underline {base case:}} \begin {align*} \upperbound \nolimits ^\pi (\blf {k+L-1})&=\measure {\stcompI {\subSpace }{k+L-1}}\sup _{\states {k+L-1}\in \stcompI {\subSpace }{k+L-1}}R_t+\gamma \expectation {\upperbound (\blf {k+L})}{\observationsRV {k+L}}\\ &=\measure {\stcompI {\subSpace }{k+L-1}}\sup _{\states {k+L-1}\in \stcompI {\subSpace }{k+L-1}}R_t\;,\\ \bar {V}^\pi (\blf {k+L-1}) & =\partialexpectation {\boldsymbol {R}_t}{\subSpaceI {k+L-1}} +\gamma \expectation {\bar {V}^\pi (\blf {k+L})}{\observationsRV {k+L}}\\ &=\partialexpectation {\boldsymbol {R}_{k+L-1}}{\subSpaceI {k+L-1}}\;,\\ V^\pi (\blf {k+L-1})&=\expectation {\boldsymbol {R}_{k+L-1}}{\statesRV {k+L-1}} +\gamma \expectation {V^\pi (\blf {k+L})}{\observationsRV {k+L}}\\ &=\expectation {\boldsymbol {R}_{k+L-1}}{\statesRV {k+L-1}}\;. \end {align*} Put together we find that the inequality holds as it is a direct consequence of \cref {thm:general_bounds} for $\expectation {\boldsymbol {R}_{k+L-1}}{\statesRV {k+L-1}}$. \par \textbf {\underline {induction step:}} Let us assume that $V^\pi (\blf {t+1})-\bar {V}^\pi (\blf {t+1})\leq \upperbound (\blf {t+1})$ then \begin {align*} V^\pi (\blf {t})&-\bar {V}^\pi (\blf {t})\\ \begin {split} &=\expectation {R(\blf {t}(\statesRV {t}),\statesRV {t},\pi (\blf {t}))}{\statesRV {t}}-\partialexpectation {R(\blf {t}(\statesRV {t}),\statesRV {t},\pi (\blf {t}))}{\subSpaceI {t}} \\ &\phantomeq +\gamma \left (\expectation {V^\pi (\blf {t+1})-\bar {V}^\pi (\blf {t+1})}{\observationsRV {t+1}}\right ) \end {split} \\ \begin {split} &\leq \expectation {R(\blf {t}(\statesRV {t}),\statesRV {t},\pi (\blf {t}))}{\statesRV {t}}-\partialexpectation {R(\blf {t}(\statesRV {t}),\statesRV {t},\pi (\blf {t}))}{\subSpaceI {t}} \\ &\phantomeq +\gamma \left (\expectation {\upperbound (\blf {t+1})}{\observationsRV {t+1}}\right ) \end {split} \\ &\leq \measure {\subSpaceI {t+1}}\sup _{\stcompI {\subSpace }{t+1}}R(\blf {t}(\statesRV {t}),\statesRV {t},\pi (\blf {t}))+\gamma \left (\expectation {\upperbound (\blf {t+1})}{\observationsRV {t+1}}\right )\qed \end {align*}\end{proof}

\makeatletter\Hy@SaveLastskip\label{proofsection:prAtEndxix}\ifdefined\pratend@current@sectionlike@label\immediate\write\@auxout{\string\gdef\string\pratend@section@for@proofxix{\pratend@current@sectionlike@label}}\fi\Hy@RestoreLastskip\makeatother\begin{proof}[Proof of \pratendRef{thm:prAtEndxix}]\phantomsection\label{proof:prAtEndxix}Beginning with \eqref {eq:value_function} we look for bounds on $\expectation {\reward {\blf {l},\pi _l,\blf {l+1}}}{\observationsRV {k+1:l+1}\mid \blf {k},\pi }$. Applying \cref {thm:general_bounds} leads us directly to the bounds for a single time step. Subsequently we sum over all time-steps.\end{proof}

\makeatletter\Hy@SaveLastskip\label{proofsection:prAtEndxx}\ifdefined\pratend@current@sectionlike@label\immediate\write\@auxout{\string\gdef\string\pratend@section@for@proofxx{\pratend@current@sectionlike@label}}\fi\Hy@RestoreLastskip\makeatother\begin{proof}[Proof of \pratendRef{thm:prAtEndxx}]\phantomsection\label{proof:prAtEndxx}Proof by induction: \par \textbf {\underline {base case:}} \begin {align*} \upperbound \nolimits ^\pi (\blf {k+L-1})&=\measure {\stcompI {\subSpace }{k+L}\mid \blf {k+L-1},\pi }\Bigl (\sup _{\stcompI {\subSpace }{k+L}}\reward {\blf {k+L-1},\pi _t,\blf {k+L}}+\gamma \sup _{\stcompI {\subSpace }{k+L}}\bar {V}^\pi (\blf {k+L})\Bigr )\\ &+ \gamma \Bigl (\measure {\stcompI {\subSpace }{k+L}\mid \blf {t},\pi }\sup _{\stcompI {\subSpace }{k+L}}\lowerbound (\blf {k+L})+\partialexpectation {\lowerbound (\blf {k+L})}{\subSpaceI {k+L}\mid \blf {k+L-1},\pi }\Bigr )\\ &=\measure {\stcompI {\subSpace }{k+L}\mid \blf {k+L-1},\pi }\Bigl (\sup _{\stcompI {\subSpace }{k+L}}\reward {\blf {k+L-1},\pi _t,\blf {k+L}}\Bigr )\;,\\ \bar {V}^\pi (\blf {k+L-1}) &=\partialexpectation {\reward {\blf {k+L-1},\pi _{k+L-1},\blf {k+L}}}{\subSpaceI {k+L}\mid \blf {k+L-1},\pi }+\gamma \partialexpectation {\bar {V}^\pi (\blf {k+L})}{\subSpaceI {k+L}\mid \blf {k+L-1},\pi }\\ &=\partialexpectation {\reward {\blf {k+L-1},\pi _{k+L-1},\blf {k+L}}}{\subSpaceI {k+L}\mid \blf {k+L-1},\pi }\;,\\ V^\pi (\blf {k+L-1})&=\expectation {\reward {\blf {k+L-1},\pi _{k+L-1},\blf {k+L}}}{\observationsRV {k+L}\mid \blf {k+L-1},\pi }+\gamma \expectation {V^\pi (\blf {k+L})}{\observationsRV {k+L}}\\ &=\expectation {\reward {\blf {k+L-1},\pi _{k+L-1},\blf {k+L}}}{\observationsRV {k+L}\mid \blf {k+L-1},\pi }\;. \end {align*} Put together we find that the inequality holds as it is a direct consequence of \cref {thm:general_bounds} for $\expectation {\reward {\blf {k+L-1},\pi _{k+L-1},\blf {k+L}}}{\observationsRV {k+L}\mid \blf {k+L-1},\pi }$. \par \textbf {\underline {induction step:}} , let us assume that $V^\pi (\blf {t+1})-\bar {V}^\pi (\blf {t+1})\leq \upperbound (\blf {t+1})$ then \begin {align*} V^\pi (\blf {t})&-\bar {V}^\pi (\blf {t})\\ \begin {split} =&\expectation {\reward {\blf {t},\pi _t,\blf {t+1}}}{\observationsRV {t+1}}-\partialexpectation {\reward {\blf {t},\pi _t,\blf {t+1}}}{\subSpaceI {t+1}}\\ &+\gamma \left (\expectation {V^\pi (\blf {t+1})}{\observationsRV {t+1}}-\partialexpectation {\bar {V}^\pi (\blf {t+1})}{\subSpaceI {t+1}}\right ) \end {split}\\ \begin {split} \leq &\measure {\stcompI {\subSpace }{t+1}}\sup _{\stcompI {\subSpace }{t+1}}\reward {\blf {t},\pi _t,\blf {t+1}}\\ &+\partialexpectation {\reward {\blf {t},\pi _t,\blf {t+1}}}{\subSpaceI {t+1}}-\partialexpectation {\reward {\blf {t},\pi _t,\blf {t+1}}}{\subSpaceI {t+1}}\\ &+\gamma \measure {\stcompI {\subSpace }{t+1}}\sup _{\stcompI {\subSpace }{t+1}}V^\pi (\blf {t+1})+\gamma \left (\partialexpectation {V^\pi (\blf {t+1})}{\subSpaceI {t+1}}-\partialexpectation {\bar {V}^\pi (\blf {t+1})}{\subSpaceI {t+1}}\right ) \end {split}\\ \begin {split} \leq &\measure {\stcompI {\subSpace }{t+1}}\sup _{\stcompI {\subSpace }{t+1}}\reward {\blf {t},\pi _t,\blf {t+1}}\\ &+\gamma \left (\measure {\stcompI {\subSpace }{t+1}}\sup _{\stcompI {\subSpace }{t+1}}V^\pi (\blf {t+1})+\partialexpectation {\upperbound (\blf {t+1})}{\subSpaceI {t+1}}\right ) \end {split}\\ \begin {split} =&\measure {\stcompI {\subSpace }{t+1}}\sup _{\stcompI {\subSpace }{t+1}}\reward {\blf {t},\pi _t,\blf {t+1}}\\ &+\gamma \measure {\stcompI {\subSpace }{t+1}}\sup _{\stcompI {\subSpace }{t+1}}\left (V^\pi (\blf {t+1})-\bar {V}^\pi (\blf {t+1})+\bar {V}^\pi (\blf {t+1})\right ) \\ &+\gamma \partialexpectation {\upperbound (\blf {t+1})}{\subSpaceI {t+1}} \end {split}\\ \begin {split} \leq &\measure {\stcompI {\subSpace }{t+1}}\sup _{\stcompI {\subSpace }{t+1}}\reward {\blf {t},\pi _t,\blf {t+1}}\\ &+\gamma \measure {\stcompI {\subSpace }{t+1}}\sup _{\stcompI {\subSpace }{t+1}}\left (\upperbound (\blf {t+1})+\bar {V}^\pi (\blf {t+1})\right )+\gamma \partialexpectation {\upperbound (\blf {t+1})}{\subSpaceI {t+1}} \end {split}\\ \begin {split} \leq &\measure {\stcompI {\subSpace }{t+1}}\sup _{\stcompI {\subSpace }{t+1}}\reward {\blf {t},\pi _t,\blf {t+1}}\\ &+\gamma \measure {\stcompI {\subSpace }{t+1}}\left (\sup _{\stcompI {\subSpace }{t+1}}\upperbound (\blf {t+1})+\sup _{\stcompI {\subSpace }{t+1}}\bar {V}^\pi (\blf {t+1})\right )+\gamma \partialexpectation {\upperbound (\blf {t+1})}{\subSpaceI {t+1}}\qed \end {split} \end {align*}\end{proof}

\makeatletter\Hy@SaveLastskip\label{proofsection:prAtEndxxi}\ifdefined\pratend@current@sectionlike@label\immediate\write\@auxout{\string\gdef\string\pratend@section@for@proofxxi{\pratend@current@sectionlike@label}}\fi\Hy@RestoreLastskip\makeatother\begin{proof}[Proof of \pratendRef{thm:prAtEndxxi}]\phantomsection\label{proof:prAtEndxxi}Proof by induction: \par \textbf {\underline {base case:}} \begin {align*} \upperbound \nolimits ^\pi (\blf {k+L-1})&=\measure {\stcompI {\subSpace }{k+L}}\sup _{\stcompI {\subSpace }{k+L}}\reward {\blf {k+L-1},\pi _{k+L-1},\blf {k+L}}+\gamma \expectation {\upperbound (\blf {k+L})}{\observationsRV {k+L}}\\ &=\measure {\stcompI {\subSpace }{k+L}}\sup _{\stcompI {\subSpace }{k+L}}\reward {\blf {k+L-1},\pi _{k+L-1},\blf {k+L}}\;,\\ \bar {V}^\pi (\blf {k+L-1})&=\partialexpectation {\reward {\blf {k+L-1},\pi _{k+L-1},\blf {k+L}}}{\subSpaceI {k+L}}+\gamma \expectation {\bar {V}^\pi (\blf {k+L})}{\observationsRV {k+L}}\\ &=\partialexpectation {\reward {\blf {k+L-1},\pi _{k+L-1},\blf {k+L}}}{\subSpaceI {k+L}}\;,\\ V^\pi (\blf {k+L-1})&=\expectation {\reward {\blf {k+L-1},\pi _{k+L-1},\blf {k+L}}}{\observationsRV {k+L}\mid \blf {k+L-1},\pi }+\gamma \expectation {V^\pi (\blf {k+L})}{\observationsRV {k+L}}\\ &=\expectation {\reward {\blf {k+L-1},\pi _{k+L-1},\blf {k+L}}}{\observationsRV {k+L}\mid \blf {k+L-1},\pi }\;. \end {align*} Put together we find that the inequality holds as it is a direct consequence of \cref {thm:general_bounds} for $\expectation {\reward {\blf {k+L-1},\pi _{k+L-1},\blf {k+L}}}{\observationsRV {k+L}\mid \blf {k+L-1},\pi }$. \par \textbf {\underline {induction step:}} Let us assume that $V^\pi (\blf {t+1})-\bar {V}^\pi (\blf {t+1})\leq \upperbound (\blf {t+1})$ then \begin {align*} V^\pi (\blf {t})-&\bar {V}^\pi (\blf {t})\\ \begin {split} &=\expectation {\reward {\blf {t},\pi _t,\blf {t+1}}}{\observationsRV {t+1}}-\partialexpectation {\reward {\blf {t},\pi _t,\blf {t+1}}}{\subSpaceI {t+1}}\\ &\phantomeq +\gamma \Bigl (\expectation {V^\pi (\blf {t+1})}{\observationsRV {t+1}}-\expectation {\bar {V}^\pi (\blf {t+1})}{\observationsRV {t+1}}\Bigr ) \end {split}\\ \begin {split} &\leq \measure {\stcompI {\subSpace }{t+1}}\sup _{\stcompI {\subSpace }{t+1}}\reward {\blf {t},\pi _t,\blf {t+1}}\\ &\phantomeq +\partialexpectation {\reward {\blf {t},\pi _t,\blf {t+1}}}{\subSpaceI {t+1}}-\partialexpectation {\reward {\blf {t},\pi _t,\blf {t+1}}}{\subSpaceI {t+1}}\\ &\phantomeq +\gamma \expectation {V^\pi (\blf {t+1})-\bar {V}^\pi (\blf {t+1})}{\observationsRV {t+1}} \end {split}\\ &\leq \measure {\stcompI {\subSpace }{t+1}}\sup _{\stcompI {\subSpace }{t+1}}\reward {\blf {t},\pi _t,\blf {t+1}}+\gamma \expectation {\upperbound (\blf {t+1})}{\observationsRV {t+1}}\qed \end {align*}\end{proof}

\makeatletter\Hy@SaveLastskip\label{proofsection:prAtEndxxii}\ifdefined\pratend@current@sectionlike@label\immediate\write\@auxout{\string\gdef\string\pratend@section@for@proofxxii{\pratend@current@sectionlike@label}}\fi\Hy@RestoreLastskip\makeatother\begin{proof}[Proof of \pratendRef{thm:prAtEndxxii}]\phantomsection\label{proof:prAtEndxxii}We begin by applying Bayes theorem to $\condEntropy {\statesRV {}}{\observationsRV {}}$ \begin {equation} \expectation {\condEntropy {\statesRV {}}{\observationsRV {}}}{\observationsRV {}}\equiv \condEntropy {\statesRV {}}{\observationsRV {}}=\entropy {\statesRV {}}+\condEntropy {\observationsRV {}}{\statesRV {}}-\entropy {\observationsRV {}}\;. \end {equation} The term $\entropy {\statesRV {}}$ is independent of $\observationsRV {}$ and so remains unchanged. The next two terms we bound via \cref {thm:observation_bounds} and \cref {thm:normalizer_bounds}. Collecting the bounds on all the terms results directly in the bounds mentioned in the theorem. \begin {equation*} \begin {split} \upperbound _\subSpace \left (\expectation {\log C_{pq}}{\observationsRV {}}\right )&=-\frac {\log p}{p}-\frac {\log q}{q}-\partialexpectation {\log m_{\observations {}}}{\subSpace }-\log m_{\states {}}\\ &\phantomeq + \partialexpectation {\log \left (m_{\states {}}M_{\states {}}^{q-1}+m_{\observations {}}M_{\observations {}}^{p-1}\right )}{\subSpace }\\ &\phantomeq +\measure {\stcomp {\subSpace }}\log \Biggl ( m_{\states {}}M_{\states {}}^{q-1}+\inf _{\observations {}\in \stcomp {\subSpace }}m_{\observations {}}\Biggl (\sup _{\observations {}\in \stcomp {\subSpace }}M_{\observations {}}\Biggr )^{p-1}\Biggr ) \\ &\phantomeq -\measure {\stcomp {\subSpace }}\log \inf _{\observations {}\in \stcomp {\subSpace }}m_{\observations {}}\;, \end {split} \end {equation*} where $M_{\states {}}\triangleq \sup \prob {\states {}}$ and $m_{\states {}}\triangleq \inf \prob {\states {}}$.\end{proof}

\makeatletter\Hy@SaveLastskip\label{proofsection:prAtEndxxiii}\ifdefined\pratend@current@sectionlike@label\immediate\write\@auxout{\string\gdef\string\pratend@section@for@proofxxiii{\pratend@current@sectionlike@label}}\fi\Hy@RestoreLastskip\makeatother\begin{proof}[Proof of \pratendRef{thm:prAtEndxxiii}]\phantomsection\label{proof:prAtEndxxiii}We begin by expressing the conditional entropy as follows \begin {align*} \condEntropy {\observationsRV {}}{\statesRV {}} & =-\int \int \prob {\states {}}\probcond {\observations {}{}}{\states {}}\log \probcond {\observations {}{}}{\states {}}\D \observations {}\D \states {}\\ & =-\int \int \prob {\observations {}}\probcond {\states {}}{\observations {}}\log \probcond {\observations {}{}}{\states {}}\D \states {}\D \observations {}\\ & =-\expectation {\expectation {\log \probcond {\observationsRV {}}{\statesRV {}}}{\statesRV {}\mid \observationsRV {}}}{\observationsRV {}}, \label {eq:entropy_observation} \end {align*} As a direct consequence of \cref {thm:general_bounds} \begin {equation*} \condEntropy {\observationsRV {}}{\statesRV {}}+\partialexpectation {\expectation {\log \probcond {\observationsRV {}}{\statesRV {}}}{\statesRV {}\mid \observationsRV {}}}{\subSpace }\leq -\measure {\stcomp {\subSpace }}\inf _{\observations {}\in \stcomp {\subSpace }}\expectation {\log \probcond {\observations {}}{\statesRV {}}}{\statesRV {}\mid \observations {}} \end {equation*} we can then loosen the bounds via \begin {align*} \inf _{\observations {}\in \stcomp {\subSpace }}\expectation {\log \probcond {\observations {}}{\statesRV {}}}{\statesRV {}\mid \observations {}} & \geq \log \inf _{\states {},\observations {}\in \stcomp {\subSpace }}\probcond {\observations {}}{\states {}} \\ & =\log \inf _{\observations {}\in \stcomp {\subSpace }}m_{\observations {}} \end {align*}\end{proof}

\makeatletter\Hy@SaveLastskip\label{proofsection:prAtEndxxiv}\ifdefined\pratend@current@sectionlike@label\immediate\write\@auxout{\string\gdef\string\pratend@section@for@proofxxiv{\pratend@current@sectionlike@label}}\fi\Hy@RestoreLastskip\makeatother\begin{proof}[Proof of \pratendRef{thm:prAtEndxxiv}]\phantomsection\label{proof:prAtEndxxiv}Bounding the normalizer entropy ($\entropy {\observationsRV {}}$) is more difficult, and requires two bounding steps. In the first step we will use Holder's inequality and its variants~\cite {Wang77cmb} to separate the observations from the belief. We can then subsequently apply bounds of the form seen in \cref {thm:general_bounds}. \par For both upper and lower bounds we begin by bounding the normalizer: \begin {equation*} \prob {\observationsRV {}}=\int \probcond {\observationsRV {}}{\states {}}\prob {\states {}}d\states {}\;, \end {equation*} bounding above by \begin {equation} \pnorm {\probcond {\observationsRV {}}{\states {}}}{p}{\states {}}\pnorm {\prob {\states {}}}{q}{\states {}}\;,\label {eq:general_holders} \end {equation} and bounding below by~\cite {Wang77cmb} \begin {equation} C_{pq}^{-1}\pnorm {\probcond {\observationsRV {}}{\states {}}}{p}{\states {}}\pnorm {\prob {\states {}}}{q}{\states {}}\;,\label {eq:general_reverse_holders} \end {equation} where $\frac {1}{p}+\frac {1}{q}=1$, $\pnorm {\cdot }{p}{\variable }$ is the $p$\tsups {th} norm with respect to $\variable $ and \begin {equation*} C_{pq}\triangleq \frac {\frac {M_{\observations {}}^{p-1}}{m_{\states {}}}+ \frac {M_{\states {}}^{q-1}}{m_{\observations {}}}}{p^{1/p}q^{1/q}}\;, \end {equation*} with $p,q>1$, limited by \eqref {eq:general_reverse_holders}, and \begin {gather*} M_{\observations {}}\triangleq \sup _{\states {}}\probcond {\observationsRV {}}{\states {}}\;,\quad m_{\observations {}}\triangleq \inf _{\states {}}\probcond {\observationsRV {}}{\states {}}\;, \\ M_{\states {}}\triangleq \sup _{\states {}}\prob {\states {}}\;,\quad m_{\states {}}\triangleq \inf _{\states {}}\prob {\states {}}\;, \end {gather*} under the assumption that the infimum of the functions are greater than zero. \par In the following we will prove the upper bound, the lower bound is derived in a similar manner but for $C_{pq}=1$. Applying inequalities \eqref {eq:reverse_holders} and \eqref {eq:bound_upper_log} we find that \begin {align*} \entropy {\observationsRV {}} & \leq \expectation {\log C_{pq}}{\observationsRV {}} -\expectation {\log \left (\pnorm {\probcond {\observationsRV {}}{\states {}}}{p}{\states {}}\pnorm {\prob {\states {}}}{q}{\states {}}\right )}{\observationsRV {}} \\ & =\expectation {\log C_{pq}}{\observationsRV {}}-\expectation {\log \pnorm {\probcond {\observationsRV {}}{\states {}}}{p}{\states {}}}{\observationsRV {}} -\log \pnorm {\prob {\states {}}}{q}{\states {}} \\ \begin {split} & \leq \expectation {\log C_{pq}}{\observationsRV {}} -\partialexpectation {\log \pnorm {\probcond {\observationsRV {}}{\states {}}}{p}{\states {}}}{\subSpace } -\log \pnorm {\prob {\states {}}}{q}{\states {}} \\ & \phantomeq -\measure {\stcomp {\subSpace }}\inf _{\observations {}\in \stcomp {\subSpace }}\log \pnorm {\probcond {\observations {}}{\states {}}}{p}{\states {}} \end {split} \\ \begin {split} & \leq \expectation {\log C_{pq}}{\observationsRV {}}-\partialexpectation {\log \pnorm {\probcond {\observationsRV {}}{\states {}}}{p}{\states {}}}{\subSpace } -\log \pnorm {\prob {\states {}}}{q}{\states {}} \\ & \phantomeq -\measure {\stcomp {\subSpace }}\left (\log m_{\norm {\observations {}}}(\stcomp {\subSpace })\right ) \end {split} \end {align*} where \begin {align*} m_{\norm {\observations {}}}(\subSpace ) & \triangleq \inf _{\observations {}\in \subSpace }\pnorm {\probcond {\observations {}}{\states {}}}{p}{\states {}}\;, \\ M_{\norm {\observations {}}}(\subSpace ) & \triangleq \sup _{\observations {}\in \subSpace }\pnorm {\probcond {\observations {}}{\states {}}}{p}{\states {}}\;. \end {align*} Via the definition of $C_{pq}$ we can further refine the bounds \begin {align*} \expectation {\log C_{pq}}{\observationsRV {}} & = -\frac {\log p}{p}-\frac {\log q}{q}-\log m_{\states {}}+\expectation {\log \left (M_{\observationsRV {}}^{p-1}+\frac {m_{\states {}}M_{\states {}}^{q-1}}{m_{\observationsRV {}}}\right )}{\observationsRV {}}\\ \begin {split} & \leq -\frac {\log p}{p}-\frac {\log q}{q}-\log m_{\states {}}+\partialexpectation {\log \left ( M_{\observationsRV {}}^{p-1}+\frac {m_{\states {}}M_{\states {}}^{q-1}}{m_{\observationsRV {}}}\right )}{\subSpace } \\ & \phantomeq +\measure {\stcomp {\subSpace }}\sup _{\observations {}\in \stcomp {\subSpace }}\log \left ( M_{\observations {}}^{p-1}+\frac {m_{\states {}}M_{\states {}}^{q-1}}{m_{\observations {}}}\right ) \end {split} \\ \begin {split} & \leq -\frac {\log p}{p}-\frac {\log q}{q}-\log m_{\states {}}-\partialexpectation {\log m_{\observationsRV {}}}{\subSpace }\\ &\phantomeq +\partialexpectation {\log \left (m_{\states {}}M_{\states {}}^{q-1}+m_{\observationsRV {}}M_{\observationsRV {}}^{p-1}\right )}{\subSpace } -\measure {\stcomp {\subSpace }}\log \inf _{\observations {}\in \stcomp {\subSpace }}m_{\observations {}}\\ & \phantomeq +\measure {\stcomp {\subSpace }}\log \Bigl ( m_{\states {}}M_{\states {}}^{q-1} +\inf _{\observations {}\in \stcomp {\subSpace }}m_{\observations {}}\Bigl (\sup _{\observations {}\in \stcomp {\subSpace }}M_{\observations {}}\Bigr )^{p-1}\Bigr ) \end {split} \end {align*}\end{proof}

\makeatletter\Hy@SaveLastskip\label{proofsection:prAtEndxxvii}\ifdefined\pratend@current@sectionlike@label\immediate\write\@auxout{\string\gdef\string\pratend@section@for@proofxxvii{\pratend@current@sectionlike@label}}\fi\Hy@RestoreLastskip\makeatother\begin{proof}[Proof of \pratendRef{thm:prAtEndxxvii}]\phantomsection\label{proof:prAtEndxxvii}$\condEntropy {\observationsRV {}}{\statesRV {}}=\sum \limits _{i=1}^{\abs {\observationsRV {}}}\condEntropy {\observationRV {}{i}}{\statesRV {}}$ assuming conditional independence of the observations, as such we can bound $\condEntropy {\observationsRV {}}{\statesRV {}}$ with a sum of bounds from \cref {thm:observation_bounds}.\end{proof}

\makeatletter\Hy@SaveLastskip\label{proofsection:prAtEndxxviii}\ifdefined\pratend@current@sectionlike@label\immediate\write\@auxout{\string\gdef\string\pratend@section@for@proofxxviii{\pratend@current@sectionlike@label}}\fi\Hy@RestoreLastskip\makeatother\begin{proof}[Proof of \pratendRef{thm:prAtEndxxviii}]\phantomsection\label{proof:prAtEndxxviii}For both bounds we begin by bounding the normalizer, \begin {equation*} \begin {split} \prob {\observationsRV {}} & =\int \probcond {\observationRV {}{1:n}}{\states {}}\prob {\states {}}\D \states {}\\ & =\int \prod _{i=1}^n\probcond {\observationRV {}{i}}{\states {}}\prob {\states {}}\D \states {} \end {split} \end {equation*} above by \begin {equation} \prob {\observationsRV {}}\leq \prod _{i=1}^{m}\pnorm {\probcond {\observationRV {}{i}}{\states {}}}{p}{\states {}}\pnorm {\prod _{j=m+1}^n\probcond {\observationRV {}{j}}{\states {}}\prob {\states {}}}{q}{\states {}} \label {eq:holders} \end {equation} and below by (see~\cite {Wang77cmb}) \begin {equation} \prob {\observationsRV {}}\geq C_{pm}^{-1}\prod _{i=1}^{m}\pnorm {\probcond {\observationRV {}{i}}{\states {}}}{p}{\states {}}\pnorm {\prod _{j=m+1}^n\probcond {\observationRV {}{j}}{\states {}}\prob {\states {}}}{q}{\states {}}\label {eq:reverse_holders} \end {equation} where $p=\frac {mq}{q-1}$ and \begin {align*} &C_{pm}\triangleq \frac {\sum _{i=1}^{m} K_i(p)+K_{m+1}(q)}{p^{m/p}q^{1/q}},\\ &K_i(p)\triangleq \frac {M_{\observation {}{i}}^{p-1}}{\displaystyle m_{\states {}}\prod _{k\neq i}m_k},&& K_{m+1}(q)\triangleq \frac {M_{\states {}}^{q-1}}{\displaystyle \prod _{k}m_{\observation {i}{}}},\\ &M_{\observation {i}{}}\triangleq \sup _{\states {}}\probcond {\observationRV {i}{}}{\states {}},&& m_{\observation {i}{}}\triangleq \inf _{\states {}}\probcond {\observationRV {i}{}}{\states {}}, \\ &M_{\states {}}\triangleq \sup _{\states {}}\prod _{j=m+1}^n\probcond {\observationRV {}{j}}{\states {}}\prob {\states {}},&& m_{\states {}}\triangleq \inf _{\states {}}\prod _{j=m+1}^n\probcond {\observationRV {}{j}}{\states {}}\prob {\states {}}, \end {align*} under the assumption that the infimum of the functions is greater than zero. \par In the following we will prove the upper bound, the lower bound is derived in a similar manner but for $C_{pm}=1$. Applying inequalities \eqref {eq:reverse_holders}, and proposition \eqref {thm:bound_log} we find that entropy of the normalizer is bounded above \begin {small} \begin {align} \begin {split} \entropy {\observationsRV {}} & \leq \expectation {\log C_{pm}}{\observationRV {}{1:n}} -\expectation {\sum _{i=1}^{m}\log \left (\pnorm {\probcond {\observationRV {}{i}}{\states {}}}{p}{\states {}}\right )}{\observationRV {}{1:n}}\\ &\phantomeq -\expectation {\log \pnorm {\prod _{j=m+1}^n\probcond {\observationRV {}{j}}{\states {}}\prob {\states {}}}{q}{\states {}}}{\observationRV {}{1:n}} \end {split}\\ \begin {split} & =\expectation {\log C_{pm}}{\observationRV {}{1:n}} -\sum _{i=1}^{m}\expectation {\log \left (\pnorm {\probcond {\observationRV {}{i}}{\states {}}}{p}{\states {}}\right )}{\observationRV {}{i}}\\ &\phantomeq -\expectation {\log \pnorm {\prod _{j=m+1}^n\probcond {\observationRV {}{j}}{\states {}}\prob {\states {}}}{q}{\states {}}}{\observationRV {}{m+1:n}} \end {split}\\ \begin {split} & \leq \expectation {\log C_{pm}}{\observationRV {}{1:n}} -\sum _{i=1}^{m}\partialexpectation {\log \left (\pnorm {\probcond {\observationRV {}{i}}{\states {}}}{p}{\states {}}\right )}{\subSpace _i}\\ &\phantomeq -\sum _{i=1}^{m}\measure {\stcompI {\subSpace }{i}}\inf _{\observation {}{i}\in \subSpace _i}\log \left (\pnorm {\probcond {\observation {}{i}}{\states {}}}{p}{\states {}}\right ) \\ &\phantomeq -\expectation {\log \pnorm {\prod _{j=m+1}^n\probcond {\observationRV {}{j}}{\states {}}\prob {\states {}}}{q}{\states {}}}{\observationRV {}{m+1:n}} \end {split} \\ \begin {split} & \leq \expectation {\log C_{pm}}{\observationRV {}{1:n}}-\sum _{i=1}^{m}\partialexpectation {\log \left (\pnorm {\probcond {\observationRV {}{i}}{\states {}}}{p}{\states {}}\right )}{\subSpace _i}\\ & \phantomeq -\sum _{i=1}^{m}\measure {\stcompI {\subSpace }{i}}\log m_{\norm {\observation {}{i}}}(\stcompI {\subSpace }{i})-\expectation {\log \pnorm {\prod _{j=m+1}^n\probcond {\observationRV {}{j}}{\states {}}\prob {\states {}}}{q}{\states {}}}{\observationRV {}{m+1:n}} \end {split} \end {align} \end {small} Via the definition of $C_{pm}$ we can further refine the bound \begin {align*} \expectation {\log C_{pm}}{\observationRV {}{1:n}} & =-\frac {m\log p}{p}-\frac {\log q}{q}+\expectation {\log \frac {\sum _{i=1}^{m} M_{\observation {}{i}}^{p-1}m_{\observation {}{i}}+M_{\states {}}^{q-1}m_{\states {}}}{m_{\states {}}\prod _{i=1}^{m}m_{\observation {}{i}}}}{\observationRV {}{1:n}}\\ \begin {split} & \leq -\frac {m\log p}{p}-\frac {\log q}{q}\\ & \phantomeq +\E _{\observationRV {}{m+1:n}}\Biggl [\partexp _{\subSpace _1\times \cdots \times \subSpace _m}\Biggl [ \log \frac {\sum _{i=1}^{m}M_{\observation {}{i}}^{p-1}m_{\observation {}{i}}+M_{\states {}}^{q-1}m_{\states {}}}{m_{\states {}}\prod _{i=1}^{m}m_{\observation {}{i}}}\Biggr ] \\ &\phantomeq +\left (1-\prod _{i=1}^m\measure {\subSpace _i}\right )\sup _{\observation {}{1:m}\in \stcomp {{\left (\subSpace _1\times \cdots \times \subSpace _m\right )}}} \log \frac {\sum _{i=1}^{m} M_{\observation {}{i}}^{p-1}m_{\observation {}{i}}+M_{\states {}}^{q-1}m_{\states {}}}{m_{\states {}}\prod _{i=1}^{m}m_{\observation {}{i}}}\Biggr ] \end {split}\\ \begin {split} & \leq -\frac {m\log p}{p}-\frac {\log q}{q}\\ & \phantomeq -\prod _{i=1}^m\measure {\subSpace _i}\Biggl (\expectation {\log m_{\states {}}}{\observationRV {}{m+1:n}} +\sum _{j=1}^m\frac {\partialexpectation {\log m_j}{\subSpace _j}}{\measure {\subSpace _j}}\Biggr ) \\ & \phantomeq +\E _{\observationRV {}{m+1:n}}\Biggl [\partexp _{\subSpace _1}\Biggl [\dotsi \partexp _{\subSpace _m}\Biggl [ \log \Biggl (\sum _{i=1}^{m} M_{\observation {}{i}}^{p-1}m_{\observation {}{i}} +M_{\states {}}^{q-1}m_{\states {}}\Biggr )\Biggr ]\dotsi \Biggr ]\Biggr ] \\ & \phantomeq +\left (1-\prod _{i=1}^m\measure {\subSpace _i}\right )\Biggl (-\sum _{i=1}^m\log \inf m_{\observation {}{i}} \\ & \phantomeq +\E _{\observationRV {}{m+1:n}}\Bigl [-\log m_{\states {}} +\log \Bigl (\sum _{i=1}^{m}\left (\sup M_{\observation {}{i}}\right )^{p-1}\inf m_{\observation {}{i}} +M_{\states {}}^{q-1}m_{\states {}}\Bigr )\Bigr ]\Biggr ) \end {split} \end {align*}\end{proof}

\makeatletter\Hy@SaveLastskip\label{proofsection:prAtEndxxix}\ifdefined\pratend@current@sectionlike@label\immediate\write\@auxout{\string\gdef\string\pratend@section@for@proofxxix{\pratend@current@sectionlike@label}}\fi\Hy@RestoreLastskip\makeatother\begin{proof}[Proof of \pratendRef{thm:prAtEndxxix}]\phantomsection\label{proof:prAtEndxxix}From \cref {thm:entropy_high_dim_bounds}, if we take the global extremes and completely eliminate the observations we trivially arrive at the desired statement. \par For this case: \begin {equation*} \begin {split} \upperbound _{\da {}{\prime }}\left (\expectation {\log C_{pm}}{\observationsRV {}}\right )&=-\frac {m\log p}{p}-\frac {\log q}{q}-\sum _{f_i\in \mathcal {F}(\da {\textup {diff}}{})}\log \inf m_{f_i}-\expectation {\log m_{\states {}}}{\observationsRV {}{}\mid \da {}{\prime }}\\ &\phantomeq +\E _{\observationsRV {}{}\mid \da {}{\prime }}\left [\log \left (\sum _{f_i\in \mathcal {F}(\da {\textup {diff}}{})}\left (\sup M_{f_i}\right )^{p-1}\inf m_{f_i}+M_{\states {}}^{q-1}m_{\states {}}\right )\right ]\;, \end {split} \end {equation*} where \begin {align*} &M_{f_i}\triangleq \sup _{\states {}}\probcond {\observationRV {i}{}}{\states {}}\;,&& m_{f_i}\triangleq \inf _{\states {}}\probcond {\observationRV {i}{}}{\states {}}\;, \\ &M_{\states {}}\triangleq \sup _{\states {}}\prod _{f_i\in \mathcal {F}(\da {}{\prime })}f_i\prob {\states {}}\;,&& m_{\states {}}\triangleq \inf _{\states {}}\prod _{f_i\in \mathcal {F}(\da {}{\prime })}f_i\prob {\states {}}\;. \end {align*}\end{proof}
